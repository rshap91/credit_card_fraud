{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.covariance import EmpiricalCovariance, EllipticEnvelope, MinCovDet\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, cophenet, set_link_color_palette\n",
    "from scipy.spatial.distance import squareform, mahalanobis\n",
    "from fastcluster import linkage, pdist\n",
    "\n",
    "# saving models\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# incase we want to try some cleaning steps to see if it improves the model\n",
    "import Clean_Function_Helpers as cfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "SEED = 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Taking two different approaches. \n",
    "\n",
    "    1. Try to model the difference between real and fraudulent charges.\n",
    "        - Classifiers like Logistic Regression, NaiveBayes, Tree Ensembles etc\n",
    "        - Sampling approaches over vs undersampling\n",
    "    2. Try to identify core boundary of real charges and identify anything outside this boundary as fraudulent.\n",
    "        - Covariance estimates, Local Outlier Factor, Clustering, One Class SVM, Hierarchical Clustering, \n",
    "        Model-based bayesian clustering.\n",
    "        \n",
    "This notebook focuses on the second approach: using robust statistical methods as well as un-supervised learning to identify outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.Class.value_counts()/df.Class.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will test different transforms of the data\n",
    "\n",
    "sub_cols = df.columns.drop(['Time', 'Class'])\n",
    "\n",
    "scaled_df = cfh.scale_data(df, MinMaxScaler(), sub_cols)\n",
    "deskewed = cfh.deskew_df(scaled_df, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[sub_cols]\n",
    "y = df.Class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Covariance Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCD is a method to compute a robust estimate for mean and covariance of a multivariate gaussian distributed dataset.\n",
    "Empirically computing mean and covariance is known to be very sensitive to outliers, so MCD finds a _core subset_ of the data that best represents the underlying distribution. From these robust estimates, we can determine outliers by a points (usually Mahalanobis) distance to the robust mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE Sklearn spits continually spits out RuntimeWarnings on the regular dataset leading me to believe that the data is not well approximated by a normal distribution. Running the Elliptic Envelope on scaled-deskewed data seems to solve the issue._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=EllipticEnvelope(assume_centered=True, contamination=0.1, random_state=1111,\n",
       "         store_precision=True, support_fraction=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'contamination': [0.001, 0.005, 0.01], 'support_fraction': [0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(scorer), verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = deskewed[sub_cols]\n",
    "\n",
    "params = {\n",
    "    'contamination': [0.001,0.005, 0.01 0.1],\n",
    "    'support_fraction': [0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "def scorer(y, ypred):\n",
    "    \"Calculate F1 Score for Elliptic Envelope labels\"\n",
    "    ypred = np.where(ypred>0, 0, 1)\n",
    "    return metrics.f1_score(y,ypred)\n",
    "scorer = metrics.make_scorer(scorer)\n",
    "\n",
    "# THIS TAKES 2 HOURS TO RUN\n",
    "ee = EllipticEnvelope(assume_centered=True,random_state=SEED)\n",
    "grid = GridSearchCV(ee, params, scorer, cv=4)\n",
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42045984408933085\n",
      "{'contamination': 0.001, 'support_fraction': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(assume_centered=True, contamination=0.001, random_state=1111,\n",
       "         store_precision=True, support_fraction=0.7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5456885456885457\n",
      "0.43089430894308944\n",
      "0.743859649122807\n"
     ]
    }
   ],
   "source": [
    "x = deskewed[sub_cols]\n",
    "\n",
    "ee = EllipticEnvelope(assume_centered=True, contamination=0.001, support_fraction=0.7,random_state=SEED)\n",
    "ee.fit(x,y)\n",
    "ypred = np.where(ee.predict(x)>0, 0, 1)\n",
    "print(metrics.f1_score(y,ypred))\n",
    "print(metrics.recall_score(y,ypred))\n",
    "print(metrics.precision_score(y,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use predictions as features, or maybe even better would be to feed in Mahalanobis distances from best mcd. Or we can create a Multivariate Normal Distribution and use it's pdf to generate features for rows. Although I believe this is the same as the Mahalanobis distance just scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Outlier Factor is a way of scoring data points based on their relative densities to their nearest neighbors.\n",
    "The theory is that a “normal\" data point is expected to have a similar density to it’s neighbors, while data points with lower relative density (as compared to their neighbors) are more likely to be outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See for example below, points O1, O2, and O3 are outliers, but point O4 is not even though it's _distance_ to it's neighbors is comparable to O1 and O2. However the density of O4s neighbors is _not_ comparable to the neighbors of O1 and O2.\n",
    "\n",
    "![LOFExample](https://i.stack.imgur.com/EFB37.jpg![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lof_grid(x, y, n_neighbors_opts):\n",
    "    best_f1 = {'nn':0, 'thresh':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    best_recall = {'nn':0, 'thresh':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    best_precision = {'nn':0, 'thresh':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    \n",
    "    for nn in n_neighbors:\n",
    "        lof = LocalOutlierFactor(nn)\n",
    "        lof.fit(x,y)\n",
    "        for thresh in np.arange(-1,-3, -0.2):\n",
    "            ypred = np.where(lof.negative_outlier_factor_ < thresh, 1, 0)\n",
    "            f1 = metrics.f1_score(y,ypred)\n",
    "            recall = metrics.recall_score(y,ypred)\n",
    "            precision = metrics.precision_score(y,ypred)\n",
    "            if f1 > best_f1['f1']:\n",
    "                best_f1 = {'nn':nn, 'thresh':thresh, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "            if recall > best_recall['recall']:\n",
    "                best_recall = {'nn':nn, 'thresh':thresh, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "            if precision > best_precision['precision']:\n",
    "                best_precision = {'nn':nn, 'thresh':thresh, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "    return best_f1, best_recall, best_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Based methods are very costly, so performing the rest on sub sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25000\n",
       "1      492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interestingly, this algorithm performs way better on _unscaled_ data\n",
    "# This is very strange and suggests that dollar amount is a far more important\n",
    "# factor than the other variables\n",
    "normal_samp = df[df.Class==0].sample(25000, random_state=SEED)\n",
    "outliers = df[df.Class==1]\n",
    "samp = pd.concat([normal_samp, outliers])\n",
    "samp.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = samp[sub_cols]\n",
    "y = samp.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nn': 255, 'thresh': -1.9999999999999998, 'f1': 0.5612153708668455, 'recall': 0.6382113821138211, 'precision': 0.5007974481658692}\n",
      "\n",
      "{'nn': 285, 'thresh': -1.0, 'f1': 0.04986206191887198, 'recall': 0.991869918699187, 'precision': 0.025573839220207527}\n",
      "\n",
      "{'nn': 295, 'thresh': -2.8, 'f1': 0.4625158831003813, 'recall': 0.3699186991869919, 'precision': 0.6169491525423729}\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = np.arange(230,300, 5)\n",
    "best_f1, best_recall, best_precision = lof_grid(x,y, n_neighbors)\n",
    "\n",
    "print(best_f1)\n",
    "print()\n",
    "print(best_recall)\n",
    "print()\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[sub_cols]\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh: -1.0\n",
      "0.004118191235841053\n",
      "0.9817073170731707\n",
      "0.002063423574293929\n",
      "\n",
      "Thresh: -1.2\n",
      "0.014377209953966243\n",
      "0.8760162601626016\n",
      "0.007248082873671465\n",
      "\n",
      "Thresh: -1.4\n",
      "0.04573458400399622\n",
      "0.8373983739837398\n",
      "0.023509272467902995\n",
      "\n",
      "Thresh: -1.5999999999999999\n",
      "0.1151016875811337\n",
      "0.8109756097560976\n",
      "0.061946902654867256\n",
      "\n",
      "Thresh: -1.7999999999999998\n",
      "0.20505920344456405\n",
      "0.774390243902439\n",
      "0.11817617866004963\n",
      "\n",
      "Thresh: -1.9999999999999998\n",
      "0.269120654396728\n",
      "0.6686991869918699\n",
      "0.16845878136200718\n",
      "\n",
      "Thresh: -2.1999999999999997\n",
      "0.30254957507082153\n",
      "0.5426829268292683\n",
      "0.20974076983503534\n",
      "\n",
      "Thresh: -2.3999999999999995\n",
      "0.31601731601731603\n",
      "0.4451219512195122\n",
      "0.24496644295302014\n",
      "\n",
      "Thresh: -2.5999999999999996\n",
      "0.288695652173913\n",
      "0.33739837398373984\n",
      "0.25227963525835867\n",
      "\n",
      "Thresh: -2.8\n",
      "0.280561122244489\n",
      "0.2845528455284553\n",
      "0.2766798418972332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on full dataset\n",
    "lof = LocalOutlierFactor(best_f1['nn']) # use best f1 params\n",
    "lof.fit(x)\n",
    "for thresh in np.arange(-1,-3, -0.2):\n",
    "    print('Thresh:', thresh)\n",
    "    ypred = np.where(lof.negative_outlier_factor_ < thresh, 1, 0)\n",
    "    f1 = metrics.f1_score(y,ypred)\n",
    "    recall = metrics.recall_score(y,ypred)\n",
    "    precision = metrics.precision_score(y,ypred)\n",
    "    print(f1)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh: -1.0\n",
      "0.004139104704810854\n",
      "0.983739837398374\n",
      "0.0020739153722549547\n",
      "\n",
      "Thresh: -1.2\n",
      "0.014288325109239232\n",
      "0.8739837398373984\n",
      "0.007203042028912676\n",
      "\n",
      "Thresh: -1.4\n",
      "0.045669729880256194\n",
      "0.8333333333333334\n",
      "0.023478211074843956\n",
      "\n",
      "Thresh: -1.5999999999999999\n",
      "0.11221309152734485\n",
      "0.8048780487804879\n",
      "0.060310691440755404\n",
      "\n",
      "Thresh: -1.7999999999999998\n",
      "0.20497725448220497\n",
      "0.7784552845528455\n",
      "0.11802773497688752\n",
      "\n",
      "Thresh: -1.9999999999999998\n",
      "0.29537223340040236\n",
      "0.7459349593495935\n",
      "0.18414450577019567\n",
      "\n",
      "Thresh: -2.1999999999999997\n",
      "0.36098069900886803\n",
      "0.7032520325203252\n",
      "0.24280701754385964\n",
      "\n",
      "Thresh: -2.3999999999999995\n",
      "0.4065146579804561\n",
      "0.6341463414634146\n",
      "0.29913710450623204\n",
      "\n",
      "Thresh: -2.5999999999999996\n",
      "0.39588281868566905\n",
      "0.508130081300813\n",
      "0.324254215304799\n",
      "\n",
      "Thresh: -2.8\n",
      "0.3458646616541353\n",
      "0.37398373983739835\n",
      "0.32167832167832167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on full dataset\n",
    "lof = LocalOutlierFactor(best_precision['nn']) # use best precision params\n",
    "lof.fit(x)\n",
    "for thresh in np.arange(-1,-3, -0.2):\n",
    "    print('Thresh:', thresh)\n",
    "    ypred = np.where(lof.negative_outlier_factor_ < thresh, 1, 0)\n",
    "    f1 = metrics.f1_score(y,ypred)\n",
    "    recall = metrics.recall_score(y,ypred)\n",
    "    precision = metrics.precision_score(y,ypred)\n",
    "    print(f1)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So best params are\n",
    "nn = 295, \n",
    "thresh = -2.4, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN is a density based clustering method that labels points as outliers if they don't meet a certain threshold to belong to any nearby cluster. Points that are not within at least `eps` distance to `min_samples` other points are labeled outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def db_grid(x, y, eps_opts, min_samp_opts):\n",
    "    best_f1 = {'eps':0, 'ms':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    best_recall = {'nn':0, 'thresh':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    best_precision = {'nn':0, 'thresh':0, 'f1':0, 'recall':0, 'precision':0}\n",
    "    \n",
    "    for eps in eps_opts:\n",
    "        for mso in min_samp_opts:\n",
    "            db = DBSCAN(eps, mso)\n",
    "            db.fit(x)\n",
    "                \n",
    "            ypred = np.where(db.labels_< 0, 1, 0)\n",
    "            f1 = metrics.f1_score(y,ypred)\n",
    "            recall = metrics.recall_score(y,ypred)\n",
    "            precision = metrics.precision_score(y,ypred)\n",
    "            if f1 > best_f1['f1']:\n",
    "                best_f1 = {'eps':eps, 'ms':mso, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "            if recall > best_recall['recall']:\n",
    "                best_recall = {'eps':eps, 'ms':mso, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "            if precision > best_precision['precision']:\n",
    "                best_precision = {'eps':eps, 'ms':mso, 'f1':f1, 'recall':recall, 'precision':precision}\n",
    "    return best_f1, best_recall, best_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_samp = df[df.Class==0].sample(25000, random_state=SEED)\n",
    "outliers = df[df.Class==1]\n",
    "samp = pd.concat([normal_samp, outliers])\n",
    "samp.Class.value_counts()\n",
    "\n",
    "x = samp[sub_cols]\n",
    "y = samp.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eps': 10, 'ms': 12, 'f1': 0.3737991266375546, 'recall': 0.4349593495934959, 'precision': 0.327718223583461}\n",
      "\n",
      "{'eps': 10, 'ms': 15, 'f1': 0.36348408710217756, 'recall': 0.4410569105691057, 'precision': 0.3091168091168091}\n",
      "\n",
      "{'eps': 10, 'ms': 8, 'f1': 0.34509803921568627, 'recall': 0.35772357723577236, 'precision': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "eps_opts = np.arange(10,25, 3)\n",
    "ms_opts = [8,10,12,15]\n",
    "\n",
    "best_f1, best_recall, best_precision = db_grid(x,y, eps_opts, ms_opts)\n",
    "print(best_f1)\n",
    "print()\n",
    "print(best_recall)\n",
    "print()\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKES TOO LONG --- WHAT DO I DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eps': 10, 'ms': 12, 'f1': 0.3737991266375546, 'recall': 0.4349593495934959, 'precision': 0.327718223583461}\n"
     ]
    }
   ],
   "source": [
    "# # Test on full dataset\n",
    "# x = df[sub_cols]\n",
    "# y = df.Class\n",
    "\n",
    "\n",
    "# for d in [best_f1, best_recall, best_precision]:\n",
    "#     print(d)\n",
    "#     eps = d['eps']\n",
    "#     ms  = d['ms']\n",
    "#     db = DBSCAN(eps, ms)\n",
    "#     db.fit(x)\n",
    "    \n",
    "#     ypred = np.where(db.labels_ < 0, 1, 0)\n",
    "#     f1 = metrics.f1_score(y,ypred)\n",
    "#     recall = metrics.recall_score(y,ypred)\n",
    "#     precision = metrics.precision_score(y,ypred)\n",
    "#     print(f1)\n",
    "#     print(recall)\n",
    "#     print(precision)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df[sub_cols]\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3077725612936881\n",
      "0.5995934959349594\n",
      "0.20701754385964913\n",
      "\n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2806468440271257\n",
      "0.5467479674796748\n",
      "0.1887719298245614\n",
      "\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2785602503912363\n",
      "0.5426829268292683\n",
      "0.18736842105263157\n",
      "\n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rick.shapiro/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:1706: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28482003129890454\n",
      "0.5548780487804879\n",
      "0.19157894736842104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in [200, 250, 300, 350]:\n",
    "    print(n)\n",
    "    isf = IsolationForest(n, max_samples=0.333, max_features=0.6, contamination=0.005)\n",
    "    isf.fit(x)\n",
    "    pred = isf.predict(x)\n",
    "    ypred = np.where(pred< 0, 1, 0)\n",
    "    f1 = metrics.f1_score(y,ypred)\n",
    "    recall = metrics.recall_score(y,ypred)\n",
    "    precision = metrics.precision_score(y,ypred)\n",
    "    print(f1)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21858724218519207, {'contamination': 0.005, 'n_estimators': 250})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1981981981981982\n",
      "0.1565040650406504\n",
      "0.27017543859649124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(isf.predict(x) <0, 1, 0)\n",
    "f1 = metrics.f1_score(y,ypred)\n",
    "recall = metrics.recall_score(y,ypred)\n",
    "precision = metrics.precision_score(y,ypred)\n",
    "print(f1)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
